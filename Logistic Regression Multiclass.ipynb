{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "        \n",
    "    def thres(self,n):\n",
    "        if(n>=0.5):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def hyp(self):\n",
    "        pp= -1 * np.dot(self.X, self.theta)\n",
    "        prob= (1.0 / (1 + (np.e **(pp))))\n",
    "        newf=  np.vectorize(self.thres)\n",
    "        newp= newf(prob)\n",
    "        return prob\n",
    "    \n",
    "        \n",
    "    def get_cost(self):\n",
    "        aa= np.dot(np.log(self.hyp().transpose()), self.y)\n",
    "        bb= np.dot((np.log(1 - self.hyp().transpose())), (1- self.y))\n",
    "        coss= aa + bb\n",
    "        mcost = ((-1.0/self.m) * sum(coss))\n",
    "        return mcost\n",
    "    \n",
    "    def fscale(self):\n",
    "        self.X= self.X / (self.X.max(axis= 0) - self.X.min(axis= 0))\n",
    "        self.y= self.y / (max(self.y) - min(self.y))\n",
    "        \n",
    "    def computeStandard(self):\n",
    "        from sklearn.linear_model import LogisticRegression as LR\n",
    "        self.logreg= LR()\n",
    "        self.logreg.fit(self.X, self.y)\n",
    "\n",
    "    def process_col(self, col):\n",
    "        col= col.values\n",
    "        return col[None].transpose()\n",
    "        \n",
    "    def preprocess(self, X, y, alpha):\n",
    "        (self.m, self.n)= X.shape\n",
    "        self.columns= X.columns\n",
    "        self.X= X.values\n",
    "        self.ny= pd.get_dummies(y)\n",
    "        self.nc= len(y.unique())\n",
    "        self.nccols= y.unique()\n",
    "        self.thetas= [np.zeros(self.n+1)[None].transpose()]*self.nc\n",
    "        \n",
    "        #self.fscale()\n",
    "        #self.computeStandard()\n",
    "        self.n+=1\n",
    "        self.X= np.insert(self.X, 0, 1, axis= 1)\n",
    "        self.alpha= alpha\n",
    "       \n",
    "          \n",
    "    def fit(self, X, y, alpha= 0.1):\n",
    "        self.preprocess(X, y, alpha)\n",
    "        \n",
    "        for i in range(self.nc):\n",
    "            self.y= self.ny[self.nccols[i]]\n",
    "            self.y= self.process_col(self.y)\n",
    "            self.theta= self.thetas[i]\n",
    "            pc= math.inf\n",
    "            change= 1\n",
    "            iteration=0\n",
    "            #print(\"Change is \",change)\n",
    "            while(change>0.0000001 and iteration<=100):\n",
    "                der = (self.hyp() - self.y).transpose()\n",
    "                der = np.dot(der , self.X) * self.alpha / self.m\n",
    "                self.theta= self.theta - der.transpose()\n",
    "                self.cost= self.get_cost()\n",
    "                change= pc - self.cost\n",
    "                pc= self.cost\n",
    "                iteration += 1\n",
    "                if(iteration % 1000 == 0):\n",
    "                    print(\"{}. Cost: {}, theta: {}\".format(iteration, self.cost, self.theta.transpose()))\n",
    "            #print(\"Change is \",change)\n",
    "            print('+'*70, \"\\n{}. Final Cost: {}, theta: {}\".format(iteration, self.cost, self.theta.transpose()))\n",
    "        #print(\"sklearn: theta: \",self.logreg.intercept_, self.logreg.coef_,\"\\n\")\n",
    "        \n",
    "            \n",
    "    def predict(self, X):\n",
    "        X= X.values\n",
    "        X= np.insert(X, 0, 1, axis= 1)\n",
    "        \n",
    "        pp= -1 * np.dot(X, self.theta)\n",
    "        prob= (1.0 / (1 + (np.e **(pp))))\n",
    "        newf=  np.vectorize(self.thres)\n",
    "        newp= newf(prob)\n",
    "        return newp.transpose()[0], prob.transpose()[0]\n",
    "    \n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        return sum(y_true == y_pred) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "149  150            5.9           3.0            5.1           1.8   \n",
       "72    73            6.3           2.5            4.9           1.5   \n",
       "69    70            5.6           2.5            3.9           1.1   \n",
       "9     10            4.9           3.1            1.5           0.1   \n",
       "56    57            6.3           3.3            4.7           1.6   \n",
       "\n",
       "             Species  \n",
       "149   Iris-virginica  \n",
       "72   Iris-versicolor  \n",
       "69   Iris-versicolor  \n",
       "9        Iris-setosa  \n",
       "56   Iris-versicolor  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('Files/Iris.csv')\n",
    "#mapper= {'Iris-versicolor':1, 'Iris-setosa':2, 'Iris-virginica':3}\n",
    "#data['Species']= data['Species'].map(mapper)\n",
    "#dumm= pd.get_dummies(data['Species'])\n",
    "#data= pd.concat([data, dumm], axis=1)\n",
    "feature_cols= ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "target_col= 'Species'\n",
    "X= data[feature_cols]\n",
    "y= data[target_col]\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \n",
      "101. Final Cost: [0.69310727], theta: [[-1.68314999e-06 -1.26541925e-05 -3.91487949e-06 -1.40516964e-05\n",
      "  -5.23154629e-06]]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \n",
      "101. Final Cost: [0.69313186], theta: [[-1.68321421e-06 -9.52358778e-06 -6.09667067e-06 -4.63878582e-06\n",
      "  -1.58891005e-06]]\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \n",
      "2. Final Cost: [0.69314701], theta: [[-3.33333182e-08 -1.45133244e-07 -1.07133287e-07 -5.73327455e-09\n",
      "   1.52000189e-08]]\n"
     ]
    }
   ],
   "source": [
    "logreg= LogisticRegression()\n",
    "logreg.fit(X, y, alpha=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-72abb6a2720a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogreg\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.00025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "logreg= LogisticRegression()\n",
    "logreg.fit(X, y, alpha= 0.00025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7486979166666666\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_pred_prob= logreg.predict(X)\n",
    "result= pd.DataFrame({\"True\":y, \"Prediction\":y_pred, \"Probablity\":y_pred_prob})\n",
    "score= logreg.accuracy(y, y_pred)\n",
    "print(\"Accuracy:\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510416666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()[0] / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.7747395833333334\n",
      "theta: [[ 0.11322185  0.02873252 -0.01710249  0.0022031  -0.00049272  0.06198601\n",
      "   0.00858668]]\n",
      "intercept: [-5.74521571]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "lr= LR()\n",
    "lr.fit(X, y)\n",
    "y_pred= lr.predict(X)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score= accuracy_score(y, y_pred)\n",
    "print('Score',score)\n",
    "print('theta:', lr.coef_)\n",
    "print('intercept:', lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To be continued..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
